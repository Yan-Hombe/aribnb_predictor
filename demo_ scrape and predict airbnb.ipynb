{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from airbnb (insideairbnb) and make predictions based on it\n",
    "\n",
    "# Introduction\n",
    "This Jupyter notebook guides you through the process of downloading Airbnb data and using the data to make some predictions. The data we will be using is sourced from the Inside Airbnb project and can be accessed at the following URL: [Inside Airbnb Data](http://insideairbnb.com/get-the-data.html). In addition you can use the file to make some longitude and latitude requests on the google API.\n",
    "\n",
    "The functions needed to scrape and process the data, as well as make predictions, are all stored in the Python file \"scrape_and_predict_functions.py\". This notebook makes use of all the functions from this file, but depending on your specific requirements, you may choose to use only certain parts. To ensure proper functioning, please ensure that the \"scrape_and_predict_functions.py\" file is in the same directory as this notebook.\n",
    "\n",
    "## Note\n",
    "\n",
    "Running this notebook will create several folders in your current working directory. Be aware of this to prevent any unwanted clutter or overwriting of existing folders or files.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [1. Scraping the Data](#1.-Scraping-the-Data)\n",
    "* [2. Clean and Merge the Data](#2.-Clean-and-Merge-the-Data)\n",
    "* [3. Prediction](#3.-Prediction)\n",
    "* [4. Get Input for Prediction](#4.-Get-Input-for-Prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed packages\n",
    "import scrape_and_predict_functions as spf\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scraping the Data\n",
    "First we need to scrape the data from the website and save it in the wanted location \n",
    "to later use it for predictions. Therefore we extract the needed links from the website. We then use this links to creat a download request. Finally we store them in a folder. Keep in minde that the downloaded files are in .gz format which is a compressed csv file. In order to keep the computational and download recourses low we will restrict the scraped data to the cities of amsterdam and antwerp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all links from website which lead to the data files there are roughly 120 links\n",
    "# need internet connection because it scrapes (requests) the website\n",
    "csv_links = spf.get_links()\n",
    "\n",
    "\n",
    "# filter out only the cities you want to scrape\n",
    "# define which cities you want to download\n",
    "cities = ['amsterdam', 'antwerp']\n",
    "\n",
    "# get the link for the cities you want to scrape. They are from the scraped list of links csv_links\n",
    "csv_links = spf.get_links_certain_city(csv_links, cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to store the downloaded compressed .csv.gz files. The csv.gz contain all the scraped airbnb data\n",
    "os.makedirs('csv_files_airbnb_csv_gz', exist_ok=True)\n",
    "\n",
    "# download the files and save them in a folder with compressed .csv.gz files\n",
    "spf.download_csv_save_in_folder(csv_links, 'csv_files_airbnb_csv_gz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean and Merge the Data\n",
    "Now that we downloaded the data files we are going to extract the csv.gz file and save it as a simple .csv file. Moreover, we want to merge the file into a single dataframe in order to clean, select and tranform the data and later on do the trianing of the prediction model with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder to store the extracted files\n",
    "os.makedirs('csv_files_airbnb_extracted_csv', exist_ok=True)\n",
    "\n",
    "# extract the files from the compressed .csv.gz files and save them in a folder with extracted .csv files\n",
    "spf.extract_gz_from_to('csv_files_airbnb_csv_gz', 'csv_files_airbnb_extracted_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the data from the foler with extracted .csv files and put them into a merged dataframe\n",
    "df_merged = spf.convert_csv_to_dataframe_merge('csv_files_airbnb_extracted_csv')\n",
    "\n",
    "# apply some data cleaning such as rounding the long and lat or transforming the price into a float\n",
    "df_merged = spf.data_clean(df_merged, round_long_lat=True)\n",
    "\n",
    "# show the first 5 rows of the dataframe\n",
    "df_merged.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction\n",
    "Now we have the Dataframe in the right format to make some ML prediction. We will apply a random forest ML approach in order to make the prediction. You can choose the features according to your needs. In this case we will predict the price per night depending on the location and minimum/ maximum nights that the airbnb can be rented, whether the host is available and how many other listings the host has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of demonstration we only take a sample of the data in order to speed up the process\n",
    "# only take city of amsterdam in dataframe\n",
    "df_train = df_merged[df_merged['city'] == 'amsterdam']\n",
    "df_train = df_train.sample(frac=0.5, replace=False)\n",
    "\n",
    "\n",
    "# split the data into X (features) and y (outcome)\n",
    "X = df_train[['latitude', 'longitude', 'minimum_nights', \n",
    "               'maximum_nights', 'has_availability', 'host_listings_count']]\n",
    "\n",
    "y = df_train['price']\n",
    "\n",
    "# train the model. Can take a while\n",
    "fitmodel = spf.predict_random_forest(features = X, outcome = y, n_estimators=10, hyperparamopt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict price for a cerain set of features take one observation from the trained data\n",
    "# you can adjust the features to your liking. Please make sure it is a pandas dataframe\n",
    "predict_object = X.sample(n=1)\n",
    "print(predict_object)\n",
    "\n",
    "# predict the price for the observation\n",
    "print(\"the predicted price is\" , fitmodel.predict(predict_object))\n",
    "\n",
    "# show the actual price for the observation\n",
    "print(\"the actual price is\", y.loc[predict_object.index].values[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Input for Prediction\n",
    "\n",
    "If we only have an adress of the airbnb object we can get the long lat with the help of an google geocoding api. Furthermore, we can the neighborhood (variable of airbnb dataset) of an airbnb object with the input of long lat. In this section we will show you how to do that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get long lat with google geocoding api\n",
    "# In order to do this steps you need a functioning google cloud project\n",
    "# as well as a billing account and an enabled geocoding API. \n",
    "# More information here: https://developers.google.com/maps/documentation/elevation/cloud-setup\n",
    "# please note that there could be some costs involved\n",
    "\n",
    "\n",
    "# define API key for google geocoding API. Please enter your own API key\n",
    "api_key = None\n",
    "\n",
    "if api_key is not None:\n",
    "    # get the long and lat of of a certain street through the google maps api\n",
    "    latitude, longitude = spf.get_geocode(\"Javastraat 115I, 1094 HD Amsterdam, Netherlands\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the neighbourhood of a certain city with long and lat input \n",
    "# first we need to get a .geojson file from the airbnb website\n",
    "# they contain multipolygons of the neighbourhoods\n",
    "geojson_links = spf.get_geojson_links()\n",
    "\n",
    "# we again only want to scrape the geojson files for certain cities\n",
    "geojson_links = spf.get_geojson_links_certain_city(geojson_links, cities)\n",
    "\n",
    "# create a folder to store the geojson files\n",
    "os.makedirs('geojson_files', exist_ok=True)\n",
    "\n",
    "# download the geojson files\n",
    "spf.download_geojson_save_in_folder(geojson_links, 'geojson_files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the neighbourhood of a certain long and lat input\n",
    "# define longitude and latitude for demonstration\n",
    "input_longitude = df_merged[['longitude', 'latitude']].iloc[2442][0]\n",
    "input_latitude = df_merged[['longitude', 'latitude']].iloc[2442][1]\n",
    "\n",
    "# define the path to the geojson file\n",
    "file_path = 'geojson_files/amsterdam.geojson'\n",
    "\n",
    "# get the neighbourhood in amsterdam\n",
    "neighborhood = spf.get_neighbourhood(input_longitude, input_latitude, file_path)\n",
    "neighborhood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
